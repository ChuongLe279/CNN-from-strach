{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3966892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dc7277",
   "metadata": {},
   "source": [
    "### Convolution Layer\n",
    "- Thay def thành class\n",
    "- Convolution 1 ảnh với nhiều filter\n",
    "- Thêm hàm backprop (gradient descent) cho class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a972368",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Convolution:\n",
    "    def __init__(self, input_channels, num_filters, kernel_size, stride=1, padding=0):\n",
    "        # in_channels: số kênh đầu vào, num_filters: số filter (số kênh đàu ra)\n",
    "        self.in_channels = input_channels\n",
    "        self.out_channels = num_filters\n",
    "        # Đảm bảo kernel_size là tuple\n",
    "        if isinstance(kernel_size, int):\n",
    "            self.kernel_size = (kernel_size, kernel_size)\n",
    "        else:\n",
    "            self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        # Khởi tạo trọng số và bias (ngẫu nhiên hoặc zeros)\n",
    "        # self.weights là list các kernel \n",
    "        self.weights = np.random.randn(self.out_channels, self.in_channels, self.kernel_size[0], self.kernel_size[1])\n",
    "        self.bias = np.zeros(self.out_channels)\n",
    "        self.X_padded = None\n",
    "        \n",
    "    def forward(self, image):\n",
    "        # lay kich thuoc input va kernel\n",
    "        c, h, w = image.shape\n",
    "        hk, wk = self.kernels_size\n",
    "        filters = self.out_channels\n",
    "\n",
    "        # kiem tra so kenh hop le\n",
    "        assert c == self.out_channels, \"Error\"\n",
    "\n",
    "        #them padding (0)\n",
    "        p = self.padding\n",
    "        s = self.s\n",
    "        if p > 0:\n",
    "            input_image = np.pad(input_image, ((0, 0), (p, p), (p, p)), mode='constant')\n",
    "        \n",
    "        #Tinh kich thuoc dau ra\n",
    "        out_h = int((h - hk + 2*p) / s) + 1\n",
    "        out_w = int((w - wk + 2*p) / s) + 1\n",
    "\n",
    "        #Khoi tao gia tri dau ra\n",
    "        output = np.zeros((filters,out_h, out_w))\n",
    "\n",
    "        #tich chap tung filter\n",
    "        for f in range(filters):\n",
    "                for i in range(out_h):\n",
    "                    for j in range(out_w):\n",
    "                        region = image[:,i*s : i*s + hk, j*s : j*s + wk]\n",
    "                        output[f,i,j] = np.sum(region * self.weights[f]) + self.bias[f]\n",
    "        return output\n",
    "    \n",
    "    def backprop(self, dY, learning_rate):\n",
    "        c, out_h, out_w = dY.shape\n",
    "        dX = np.zeros_like(self.X_padded)\n",
    "        db = np.zeros_like(self.bias)\n",
    "        dW = np.zeros_like(self.weights)\n",
    "        s = self.stride\n",
    "        hk, wk = self.kernel_size\n",
    "\n",
    "        # Gradient descent\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                region = self.X_padded[:, i*s : i*s + hk, j*s : j*s + wk]\n",
    "                for f in range(self.out_channels):\n",
    "                    dW[f] += np.sum(region * (dY[f, i, j]), axis=0)\n",
    "                    dX[:, i*s : i*s + hk, j*s : j*s + wk] += self.weights[f] * dY[f, i, j]\n",
    "                    db[f] += dY[f, i, j]\n",
    "\n",
    "        # Loại bỏ lớp padding trong dX\n",
    "        p = self.padding\n",
    "        if p > 0:\n",
    "            dX = dX[:, p : -p, p : -p]\n",
    "\n",
    "        # Cập nhập trọng số\n",
    "        self.weights -= learning_rate * dW\n",
    "        self.bias -= learning_rate * db.reshape(self.bias.shape)\n",
    "        return dX                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a50759",
   "metadata": {},
   "source": [
    "### ReLU Layer\n",
    "- Thay vì dùng tham số activation trong hàm Convolution, thêm một class ReLU activation để dễ tái sử dụng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee174a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.cache = None\n",
    "    def forward(self, X):\n",
    "        self.cache = X\n",
    "        return np.maximum(0, X)\n",
    "    def backward(self, dY):\n",
    "        X = self.cache\n",
    "        dX = dY.copy()\n",
    "        dX[X <= 0] = 0\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dce6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
