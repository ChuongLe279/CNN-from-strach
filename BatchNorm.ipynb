{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e75354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b725686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps):\n",
    "    # Compute reciprocal of square root of the moving variance elementwise\n",
    "    inv = tf.cast(tf.math.sqrt(moving_var + eps), X.dtype)\n",
    "    # Scale and shift | y = gamma*x - beta\n",
    "    Y = gamma * ((X - moving_mean) / inv) + beta\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a96a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        weight_shape = [input_shape[-1],]\n",
    "\n",
    "        self.gamma = self.add_weight(\n",
    "            name = 'gamma',\n",
    "            shape = weight_shape,\n",
    "            initializer = tf.initializer.ones, \n",
    "            trainable = True\n",
    "        )\n",
    "        self.beta = self.add_weight(\n",
    "            name = 'beta',\n",
    "            shape = weight_shape,\n",
    "            initializer = tf.initializer.zeros, \n",
    "            trainable = True\n",
    "        )\n",
    "        self.moving_mean = self.add_weight(\n",
    "            name='moving_mean',\n",
    "            shape=weight_shape, \n",
    "            initializer=tf.initializers.zeros,\n",
    "            trainable=False\n",
    "        )\n",
    "        \n",
    "        self.moving_variance = self.add_weight(\n",
    "            name='moving_variance',\n",
    "            shape=weight_shape, \n",
    "            initializer=tf.initializers.ones,\n",
    "            trainable=False\n",
    "        )\n",
    "        \n",
    "        super(BatchNorm, self).build(input_shape)\n",
    "\n",
    "    def assign_moving_average(self, variable, value):\n",
    "        momentum = 0.1\n",
    "        delta = (1.0 - momentum) * variable + momentum * value\n",
    "        return variable.assign(delta)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training):\n",
    "        if training:\n",
    "            axes = list(range(len(inputs.shape) - 1))\n",
    "            batch_mean = tf.reduce_mean(inputs, axes, keepdims=True)\n",
    "            batch_variance = tf.reduce_mean(tf.math.squared_difference(\n",
    "                inputs, tf.stop_gradient(batch_mean)), axes, keepdims=True)\n",
    "            batch_mean = tf.squeeze(batch_mean, axes)\n",
    "            batch_variance = tf.squeeze(batch_variance, axes)\n",
    "            mean_update = self.assign_moving_average(\n",
    "                self.moving_mean, batch_mean)\n",
    "            variance_update = self.assign_moving_average(\n",
    "                self.moving_variance, batch_variance)\n",
    "            self.add_update(mean_update)\n",
    "            self.add_update(variance_update)\n",
    "            mean, variance = batch_mean, batch_variance\n",
    "        else:\n",
    "            mean, variance = self.moving_mean, self.moving_variance\n",
    "        output = batch_norm(inputs, moving_mean=mean, moving_var=variance,\n",
    "            beta=self.beta, gamma=self.gamma, eps=1e-5)\n",
    "        return output\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c256b",
   "metadata": {},
   "source": [
    "bn_layer = BatchNorm()\n",
    "x = bn_layer(inputs)\n",
    "--> x = BatchNorm()(inputs)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(64,))       # data: 64 features\n",
    "h = tf.keras.layers.Dense(128)(inputs)     # fully connected layer output\n",
    "x = BatchNorm()(h)   \n",
    "\n",
    "Input shape: (batch_size, n_features)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
