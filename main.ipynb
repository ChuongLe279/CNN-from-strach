{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a613360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maxpooling import maxPooling \n",
    "from softmax import softMax\n",
    "from Flatten import Flatten\n",
    "from Batchnorm import BatchNorm\n",
    "from Convolution_Function import Convolution \n",
    "from Dropout import Layer_Dropout \n",
    "from FullyConnectedLayer_Function import FullyConected\n",
    "from Convolution_Function import ReLU \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15a4537f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d7a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = Convolution(1, 8, 3) # 26x26x8 \n",
    "relu = ReLU\n",
    "batchnorm_layer = BatchNorm()\n",
    "pooling_layer = maxPooling(2, 2)  # 13x13x8 \n",
    "flatten_layer = Flatten()\n",
    "flc_layer1 = FullyConected(13*13*8, 128)\n",
    "dropout_layer1 = Layer_Dropout(0.5)\n",
    "flc_layer2 = FullyConected(128, 32)\n",
    "dropout_layer2 = Layer_Dropout(0.5)\n",
    "softmax_layer = softMax(32,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9102874",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def backward(self, dY, learning_rate):\n",
    "        \"\"\"\n",
    "        Backward pass through the CNN\n",
    "        dY: gradient of loss with respect to softmax output\n",
    "        learning_rate: learning rate for weight updates\n",
    "        \"\"\"\n",
    "        # Softmax backward\n",
    "        dY = self.layers[9].backprop(dY, learning_rate)\n",
    "        \n",
    "        # Dropout layer 2 backward\n",
    "        dY = self.layers[8].backward(dY)\n",
    "        dY = np.maximum(0, dY)  # ReLU backward\n",
    "        \n",
    "        # FC2 backward\n",
    "        dY = self.layers[7].backprop(dY, learning_rate)\n",
    "        dY = np.maximum(0, dY)  # ReLU backward (simple version)\n",
    "        \n",
    "        # Dropout layer 1 backward\n",
    "        dY = self.layers[6].backward(dY)\n",
    "        dY = np.maximum(0, dY)  # ReLU backward\n",
    "        \n",
    "        # FC1 backward\n",
    "        dY = self.layers[5].backprop(dY, learning_rate)\n",
    "        \n",
    "        # Flatten backward\n",
    "        dY = self.layers[4].backward(dY)\n",
    "        \n",
    "        # MaxPooling backward\n",
    "        dY = self.layers[3].backprop(dY)\n",
    "        \n",
    "        # BatchNorm backward (handled by Keras layer)\n",
    "        # Skip for now as it's a Keras layer\n",
    "        \n",
    "        # ReLU backward\n",
    "        dY = self.layers[1].backward(dY)\n",
    "        \n",
    "        # Convolution backward\n",
    "        dY = self.layers[0].backprop(dY, learning_rate)\n",
    "        \n",
    "        return dY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b808928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the CNN model\n",
    "cnn_model = CNN([\n",
    "    conv_layer,        # 0: Convolution\n",
    "    relu,              # 1: ReLU\n",
    "    batchnorm_layer,   # 2: BatchNorm\n",
    "    pooling_layer,     # 3: MaxPooling\n",
    "    flatten_layer,     # 4: Flatten\n",
    "    flc_layer1,        # 5: FC1\n",
    "    dropout_layer1,    # 6: Dropout1\n",
    "    flc_layer2,        # 7: FC2\n",
    "    dropout_layer2,    # 8: Dropout2\n",
    "    softmax_layer      # 9: Softmax\n",
    "])\n",
    "\n",
    "# Train the model (example with small subset and few epochs for testing)\n",
    "# Uncomment to run:\n",
    "# cnn_model.train(train_images[:100], train_labels[:100], epochs=2, batch_size=10, learning_rate=0.01)\n",
    "\n",
    "# Make predictions on test set\n",
    "# predictions = cnn_model.predict(test_images[:10])\n",
    "# print(\"Predictions:\", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
